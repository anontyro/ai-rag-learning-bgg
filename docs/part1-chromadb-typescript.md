# Part 1 — ChromaDB + TypeScript Learning Path (Boardgames RAG)

Audience: You have ChromaDB and Ollama running locally via Docker Compose and a small Express API (see `apps/api/index.ts`).
Outcome: Become productive with ChromaDB and retrieval in Node/TypeScript, using the boardgames dataset as the anchor. Prepare to bridge to local models with Ollama in Part 2.

How to use this doc:
- Each module has objectives, short readings, hands-on tasks, and a checkpoint.
- Keep your notes and decisions (e.g., chunk size, top-k) in a separate scratch file so you can iterate intentionally.

## Module 0 — Foundations

Objectives:
- Understand what vector databases do and where they fit in RAG.
- Grasp embeddings, distance metrics, and the retrieval step.

Readings:
- Concept: Vector databases, embeddings, similarity search (cosine/Euclidean/inner product).
- RAG overview: Retrieval feeding context into a generator.

Hands-on:
- Sketch the RAG pipeline you’re targeting: Ingest → (optional) Embed → Store in Chroma → Query → Rank/Filter → Feed to LLM (Part 2).

Checkpoint:
- You can explain why a vector DB is used instead of keyword search, and what a “top-k similarity search” returns.

## Dataset context — Boardgames (anchor for all modules)

We will use `data/boardgames_enriched.csv` generated by `apps/api/scripts/enrich-boardgames.ts`. Each row includes:
- `id`, `name`, `yearpublished`, global `rank` and per-genre ranks (e.g., `familygames_rank`, `strategygames_rank`, `wargames_rank`, etc.).
- Enriched text: `primaryName`, `description`.
- Attributes: `minplayers`, `maxplayers`, `playingtime`, `minage`, `is_expansion`.
- Tags: `categories`, `mechanics` (semicolon-separated strings).

Target collection name in Chroma: `boardgames`.

Example validation queries throughout this doc:
- “Top 10 family games” → sort by `familygames_rank` asc.
- “Sci‑fi wargames suggestions” → filter `categories contains 'Science Fiction'` and prefer items with `wargames_rank`.
- “Co‑op legacy games like Pandemic” → semantic match on description with cooperative/legacy hints.

## Module 1 — ChromaDB and Ollama in Docker (Local)

Objectives:
- Understand Chroma server vs. client, persistence, and your local stack.

Readings:
- Chroma server concepts: collections, documents, embeddings, metadata.
- Review your `docker-compose.yml` services:
  - `chromadb` on `http://localhost:8000` (REST)
  - `ollama` on `http://localhost:11434` (local models)
  - Persistent storage examples (e.g., SQLite under `getting-started/chroma.sqlite3`, Ollama volume for model cache)

Hands-on:
- Start services: `docker compose up -d chromadb ollama`.
- Verify Chroma: `curl http://localhost:8000/api/v1/collections`.
- Verify Ollama: `curl http://localhost:11434/api/tags`.
- Decide your URLs and document them in `.env` for the API (`CHROMA_URL`, `OLLAMA_URL`).

Checkpoint:
- From a Node REPL or script, you can `heartbeat` the Chroma server.

## Module 2 — TypeScript Client Basics

Objectives:
- Connect to Chroma from Node/TS and perform CRUD on collections.

Readings:
- Chroma TypeScript client usage (`chromadb` package) and basic methods: `ChromaClient`, `getOrCreateCollection`, `add`, `upsert`, `get`, `query`, `delete`.
- Collection options (e.g., specifying an embedding function or supplying vectors).

Hands-on:
- Create a `scripts/` directory and add simple TS scripts:
  - `scripts/create-collection.ts`: `getOrCreateCollection("docs")`.
  - `scripts/seed.ts`: add a few test documents with `ids`, `documents`, and simple `metadatas`.
  - `scripts/query.ts`: run a `query` with a small `n_results` (e.g., 3) and print ids, scores, and snippets.
- Configure the client with a base URL from env (e.g., `CHROMA_URL=http://localhost:8000`).

Checkpoint:
- You can create a collection, add items, and retrieve similar items with `query`.

## Module 3 — Embeddings in Practice

Objectives:
- Choose an embedding strategy and ensure consistent embeddings across ingest and query.

Readings:
- Embedding options: hosted APIs vs. local embeddings.
- Local-first preview (for Part 2): generating embeddings with local models and passing vectors to Chroma.

Hands-on (choose one for now; you can switch in Part 2):
- Option A (focus on Chroma first): Skip embeddings for now; rely on structured filters and later add vectors.
- Option B (local-first preview via Dockerized Ollama): Use Ollama `/api/embeddings` (e.g., `nomic-embed-text`) to generate vectors and pass them to Chroma. Track model name and dimensionality.

Key considerations:
- Chunking strategy (e.g., ~500–1,000 tokens with overlap) and stable model/version across ingest/query.
- Store embedding metadata (model name/version) at collection level or metadata for reproducibility.

Checkpoint:
- You can embed a small set of texts and store vectors in Chroma, then query with an embedded user query and see sensible results.

## Module 4 — Querying & Ranking

Objectives:
- Use similarity search effectively, interpret scores, and apply filters.

Readings:
- Distance metrics used by your embedding+Chroma setup.
- `where` and `whereDocument` filters to narrow results by metadata or content.

Hands-on:
- Structured (boardgames): implement queries for
  - Top 10 family games: sort by `familygames_rank` (ascending, non-zero/non-null first).
  - Filters: categories contains `"Science Fiction"`, mechanics contains `"Deck, Bag, and Pool Building"`, `minplayers <= 2 && maxplayers >= 2`, `playingtime <= 60`.
- If embeddings are enabled: compare pure semantic vs. hybrid (filter first → vector query) and tune `n_results`.
- Print score distributions to understand sensitivity to query phrasing.

Checkpoint:
- You can justify your default `top-k` and filtering choices for your dataset.

## Module 5 — Persistence, Scaling, and Hygiene

Objectives:
- Understand storage, backups, and collection design.

Readings:
- Persistence backends overview (e.g., SQLite for local dev), implications for backups and portability.
- Namespacing and multi-tenant patterns via collection names and metadata.

Hands-on:
- Decide a collection naming scheme (e.g., `docs:{env}`) and commit it to your README.
- Add scripts to export/import a collection (IDs + documents + metadata) for quick resets.

Checkpoint:
- You can wipe and rebuild a collection deterministically from your seed scripts.

## Module 6 — Wire Chroma into the Express API

Objectives:
- Expose minimal endpoints to ingest and search so other components (Part 2) can consume retrieval easily.
- Ground endpoints on the `boardgames` collection for practical tests.

Proposed endpoints in `apps/api/index.ts`:
- POST `/collections/:name/ingest`
  - Body: `{ documents: string[], metadatas?: object[], ids?: string[], embeddingModel?: string }`
  - Behavior: chunk (if requested), embed (A or B from Module 3), `upsert` into collection.
  - Returns: `{ upserted: number }`.
- GET `/collections/:name/search`
  - Query: `q` (string), `k` (number, default 5), `where` (JSON string), `whereDocument` (JSON string)
  - Behavior: embed the query (if vectors available), run `query`, return `{ ids, documents, metadatas, distances/scores }`.
- GET `/games/top`
  - Query: `categoryRankField` (e.g., `familygames_rank`), `limit` (default 10)
  - Behavior: fetch top N by rank from `boardgames` using metadata sort or precomputed list.

Hands-on:
- Add simple validation, error handling, and config for `CHROMA_URL`.
- Use your Module 3 embedding choice inside these endpoints.
- Test with curl or an HTTP client.

Checkpoint:
- You can ingest a few docs and retrieve relevant snippets over HTTP locally.

## Module 7 — Evaluate Retrieval Quality

Objectives:
- Build a lightweight feedback loop to improve retrieval before adding a generator.

Hands-on:
- Create a tiny golden set (queries → expected passages/ids).
- Measure hit rate@k; iterate on chunking, top-k, model choice.
- Log failures (queries with poor matches) for follow-up.

Checkpoint:
- You have a short list of decisions (chunk sizes, top-k, embedding model) with a rationale based on experiments.

---

## Deliverables by end of Part 1
- Dataset-driven artifacts:
  - `apps/api/scripts/enrich-boardgames.ts` (provided) to keep `data/boardgames_enriched.csv` fresh in batches.
  - `apps/api/scripts/ingest-boardgames.ts` to load `boardgames_enriched.csv` into Chroma collection `boardgames`.
- Scripts in `scripts/` for create/seed/query (for learning/testing outside the API if desired).
- Minimal Express endpoints: `/version`, `/db/heartbeat`, `/collections/:name/ingest`, `/collections/:name/search`, `/games/top`.
- A small golden set and notes on your retrieval configuration (top‑k, filters, model choice if using embeddings).

## Preview: Part 2 — Bridge to Ollama (Local Models)
- Use Dockerized Ollama (`http://localhost:11434`) to run local models for generation and optionally embeddings.
- Orchestrate: embed query → search Chroma → build prompt → generate answer.
- Address prompt templates, context windows, and streaming responses.
- Explore RAG patterns: stuff, map‑reduce, refine; and optional re‑ranking.

## References & Resources
- ChromaDB Docs: https://docs.trychroma.com/
- chromadb NPM package: https://www.npmjs.com/package/chromadb
- Chroma GitHub: https://github.com/chroma-core/chroma
- Docker Docs (for local server & volumes): https://docs.docker.com/
- Transformers.js (local embeddings in Node): https://xenova.github.io/transformers.js/
- Sentence Transformers (concepts & models): https://www.sbert.net/
- Ollama (local models): https://ollama.com/

## Suggested Timeline
- Day 1–2: Modules 0–2
- Day 3: Modules 3–4
- Day 4: Modules 5–6
- Day 5: Module 7 + review and prepare for Part 2
